# These are defaults. This file just demonstrates how to override some settings.
bootstrap.servers=kafka-1:19092,kafka-2:29092,kafka-3:39092

# The converters specify the format of data in Kafka and how to translate it into Connect data. Every Connect user will
# need to configure these based on the format they want their data in when loaded from or stored into Kafka
#key.converter=org.apache.kafka.connect.json.JsonConverter
#value.converter=org.apache.kafka.connect.json.JsonConverter

key.converter=org.apache.kafka.connect.storage.StringConverter
value.converter=org.apache.kafka.connect.storage.StringConverter

key.converter.schemas.enable=false
value.converter.schemas.enable=false

# The internal converter used for offsets and config data is configurable and must be specified, but most users will
# always want to use the built-in default. Offset and config data is never visible outside of Copcyat in this format.
internal.key.converter=org.apache.kafka.connect.json.JsonConverter
internal.value.converter=org.apache.kafka.connect.json.JsonConverter

internal.key.converter.schemas.enable=false
internal.value.converter.schemas.enable=false


#key.converter=io.confluent.connect.avro.AvroConverter
#key.converter.schema.registry.url=http://schema-registry:8081
#value.converter=io.confluent.connect.avro.AvroConverter
#value.converter.schema.registry.url=http://schema-registry:8081
#internal.key.converter=org.apache.kafka.connect.json.JsonConverter
#internal.value.converter=org.apache.kafka.connect.json.JsonConverter
#internal.key.converter.schemas.enable=false
#internal.value.converter.schemas.enable=false


# Flush much faster (10s) than normal, which is useful for testing/debugging
offset.flush.interval.ms=10000

plugin.path=/etc/kafka-connect/jars

group.id=kafka-connect-splunk-hec-sink
config.storage.topic=__kafka-connect-splunk-task-configs
config.storage.replication.factor=3

offset.storage.topic=__kafka-connect-splunk-offsets
offset.storage.replication.factor=3
offset.storage.partitions=25

status.storage.topic=__kafka-connect-splunk-statuses
status.storage.replication.factor=3
status.storage.partitions=5

# These are provided to inform the user about the presence of the REST host and port configs 
# Hostname & Port for the REST API to listen on. If this is set, it will bind to the interface used to listen to requests.
#rest.host.name=
rest.port=38082

# The Hostname & Port that will be given out to other workers to connect to i.e. URLs that are routable from other servers.
rest.advertised.host.name=kafka-connect-1
#rest.advertised.port=

#ssl.key.password=
#
#ssl.keystore.type=JKS
#ssl.keystore.location=
#ssl.keystore.password=
#
#ssl.truststore.type=
#ssl.truststore.password=
#ssl.truststore.location=
#
#sasl.kerberos.service.name=
#security.protocol=
#
#ssl.enabled.protocols=
#ssl.protocol=TLS
#ssl.provider=
#
#sasl.kerberos.kinit.cmd=
#
#
#ssl.cipher.suites=
#ssl.endpoint.identification.algorithm=
#ssl.keymanager.algorithm=SunX509
#ssl.trustmanager.algorithm=PKIX

# rest.advertised.host.name=localhost
# rest.host.name=localhost

